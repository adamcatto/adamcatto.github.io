---
permalink: /questions
title: "Questions"
excerpt: "Questions"
author_profile: true
redirect_from: 
  - /questions/
---

{% include base_path %}

My research directions are guided by certain questions I'm interested in answering or elucidating. Here is a list of some of them:

## Computational Membrane Biology

1. Can transcriptomic profiling predict the nanoscale proteomic organization of the cell's plasma membrane and/or organelle membranes? And how should lipidologic information be factored into the prediction model?

2. To what extent do the nanoscale organizations of cell/organelle membranes differ across healthy / diseased individuals for a given disease? And can we utilize this for more granular disease subtyping / disease progression modeling? E.g. for type 2 diabetes subtyping / progression.

3. Can nanoscale organization of cell/organelle membranes be used as a (functional) biomarker of aging? Is there a "membrane clock"?

4. How can the next generations of targeted drug delivery vehicles take into account the membranes' nanoscale organization?

## Automated Scientific/Technological Discovery

1. Can we design a system for identifying biological products as potent biotechnologies for a queried task? That is to say, can we provide as input something like "control cells via light" and receive an output of something like "channelrhodopsin"? See [this article by Ed Boyden and Brian Y. Chow](https://www.technologyreview.com/2010/01/19/206611/defining-an-algorithm-for-inventing-from-nature/) for more thoughts.

## Practical Machine Learning

1. *Preface: Lots of deep learning experiments are conducted by trial and error: starting with a basic neural network configuration, and model parameters/hyperparameters are adjusted until a desired performance measure is achieved. However, one can imagine that such a positive relative result (relative to other trials with other setups) may have been a fluke, and may not replicate on other similar datasets / other splittings of the data.* So, my question is, can we design a measure of **machine learning experiment robustness** to capture an expectation on reproducibility across data/model perturbations?

